# ğŸ§  Persisto AI

**Semantic Memory-as-a-Service (SMaaS)** for LLM-powered applications.

> Give your AI agents persistent memory â€” no vector DB setup, no boilerplate, no drift.

---

## ğŸ§© What is Persisto?

Persisto is a plug-and-play memory backend for LLM apps, agents, and chatbots. It handles:

* âœ… Memory saving, querying, and deletion
* âœ… OpenAI embedding + `pgvector` similarity search
* âœ… TTL/expiry support for short-lived memory
* âœ… Metadata filtering + structured search
* âœ… Fully working Python SDK with retries, error handling, and test script

Use Persisto to **recall facts, track preferences, or power retrieval-augmented generation (RAG)** â€” with clean APIs and no infrastructure overhead.

---

## ğŸ’¡ Why Use Persisto?

LLMs forget. Agents drift. Context disappears.
Persisto solves this with **long-term, queryable memory** that just works:

* ğŸ§  Save memory chunks by namespace
* ğŸ” Retrieve by semantic similarity and metadata filters
* â³ Expire memory after N seconds (`ttl_seconds`)
* âš™ï¸ Use a simple Python SDK or REST API
* ğŸ” Scoped by user with API key auth

You focus on building smart apps â€” Persisto handles memory.

---

## ğŸ”§ Quick Start

### 1. Install the SDK

```bash
pip install persisto-ai
```

> âš™ï¸ Alternatively, clone the repo and run `python test_sdk.py` after setting your `.env`.

---

### 2. Save a memory

```python
from persisto import PersistoClient

client = PersistoClient(api_key="your-api-key")

client.save(
    namespace="demo-agent",
    content="The user prefers concise summaries.",
    metadata={"source": "profile"}
)
```

---

### 3. Query memory

```python
results = client.query(
    namespace="demo-agent",
    query="How does the user like their output?",
    filters={"source": "profile"}
)

for r in results:
    print(r["content"], r["similarity"])
```

---

## âš™ï¸ Architecture Overview

```text
sdk/python/persisto/     # Python SDK (retry logic, typed errors)
backend/
â”œâ”€â”€ main.py              # FastAPI app entry
â”œâ”€â”€ routers/memory.py    # REST endpoints: /save, /query, /delete
â”œâ”€â”€ services/            # Embedding, DB, memory logic
â”œâ”€â”€ utils/               # Chunking, auth, helpers
```

---

## âœ… Completed Features (V1.0 + V1.5)

### ğŸ§  Memory Infrastructure

* `.save()`, `.query()`, `.delete()` APIs
* Text chunking + OpenAI embeddings
* `pgvector` top-k semantic search
* Structured filtering via metadata
* API keyâ€“based user isolation

### ğŸ§° SDK Polish

* Full Python SDK
* Retry logic via `tenacity`
* Typed SDK errors (e.g. `PersistoAuthError`, `PersistoNotFoundError`)
* `.env` support and test suite

### â³ TTL / Expiry Support

* `ttl_seconds` in `.save()`
* `expires_at` column in DB
* Expired memories excluded from queries

### ğŸªª Query History API

* `/queries/list` endpoint
* `.list_queries()` in SDK
* Filter by namespace and time

---

## ğŸ›£ï¸ Roadmap

### ğŸ”· V2.0 â€“ Power Tools for Devs *(Next)*

* Retrieval Profiles: `strict`, `fuzzy`, `recency`
* `summarize_old()` â€” LLM-based memory compression
* JS/TS SDK
* Scoped tokens + project-based auth
* TTL cleanup script (optional)

### ğŸ”¶ V3.0 â€“ Persisto Cloud *(Hosted Platform)*

* Hosted dashboard + usage metrics
* Interactive playground
* Org/project system with team access
* API keys + usage billing

### ğŸ”· V4.0 â€“ The RAG Engine *(Infra Toolkit)*

* Hybrid search (vector + keyword)
* BYO embedder + summarizer
* Declarative config: `persisto.config.json`
* LangChain / LlamaIndex adapters
* GitHub RAG chatbot template

---

## ğŸ’¼ Use Cases

* Memory for multi-turn AI agents
* Preference recall in LLM copilots
* Long-term document understanding
* Semantic search + RAG pipelines
* Personalization across sessions

---

## ğŸ“¦ Tech Stack

* Python (FastAPI, Pydantic, Requests)
* Supabase (PostgreSQL + pgvector)
* OpenAI embeddings (`text-embedding-3-small`)
* Tenacity (retry logic)
* dotenv (`.env` config for SDK)
* Future: TS SDK, hosted dashboard, LangChain adapters

---

## ğŸš€ Vision

> Persisto is building the **Vercel for RAG**
> A fully hosted, developer-first platform to deploy AI memory, retrieval, and context systems â€” in one line of code.

* No infra setup
* No vector DB config
* Just `.save()` and `.query()` memory â€” and you're live

---

## ğŸ‘‡ Try It Locally

```bash
# Start backend server
uvicorn backend.main:app --reload

# Run the test script
python test_sdk.py
```

> Configure your `.env` with your API key (from Supabase).

---

## ğŸ§  Persisto gives your AI a brain.

Build memory-aware agents.
Ship smarter assistants.
Deploy production-ready RAG in minutes.